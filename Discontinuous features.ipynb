{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 1\n",
    "\n",
    "__X__ has 3 continuous features, __Y__ is a single number.\n",
    "\n",
    "If x_0 > 0, y = x_1. Otherwise, y = x_2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.55060268 0.39245848 0.71952362] [0.39245848]\n",
      "[0.91109791 0.72489333 0.92864347] [0.72489333]\n",
      "[0.27671705 0.43487896 0.92598379] [0.92598379]\n",
      "[0.74621235 0.9549078  0.36308088] [0.9549078]\n",
      "[0.83513382 0.01825462 0.09916959] [0.01825462]\n"
     ]
    }
   ],
   "source": [
    "datasize = 10000\n",
    "\n",
    "x = np.random.uniform(low=0, high=1, size=(datasize, 3))\n",
    "y = np.zeros((datasize, 1))\n",
    "for i in range(datasize):\n",
    "    y[i, 0] = x[i, 1] if x[i, 0] > 0.5 else x[i, 2]\n",
    "\n",
    "for i in range(5):\n",
    "    print(x[i], y[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 2\n",
    "\n",
    "__X__ is the same as above, __Y__ is either -0,2 or 0,5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6768646  0.40493341 0.42927454] [0.]\n",
      "[0.02509002 0.81685613 0.753418  ] [0.999]\n",
      "[0.07716709 0.78388174 0.87425364] [0.999]\n",
      "[0.03427334 0.83868677 0.02956642] [0.999]\n",
      "[0.64022978 0.57766649 0.0621873 ] [0.]\n"
     ]
    }
   ],
   "source": [
    "datasize = 10000\n",
    "\n",
    "x = np.random.uniform(low=0, high=1, size=(datasize, 3))\n",
    "y = np.zeros((datasize, 1))\n",
    "for i in range(datasize):\n",
    "    y[i, 0] = 0 if x[i, 0] > 0.5 else 0.999\n",
    "\n",
    "for i in range(5):\n",
    "    print(x[i], y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(3, input_shape=(3,)),\n",
    "    #Activation('relu'),\n",
    "    Dense(3),\n",
    "    Activation('relu'),\n",
    "    Dense(1),\n",
    "    Activation('relu'),\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10000/10000 [==============================] - 0s 48us/step - loss: 0.2522\n",
      "Epoch 2/100\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.0996\n",
      "Epoch 3/100\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.0417\n",
      "Epoch 4/100\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.0359\n",
      "Epoch 5/100\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.0318\n",
      "Epoch 6/100\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.0279\n",
      "Epoch 7/100\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.0239\n",
      "Epoch 8/100\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.0203\n",
      "Epoch 9/100\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.0171\n",
      "Epoch 10/100\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 0.0146\n",
      "Epoch 11/100\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.0129\n",
      "Epoch 12/100\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.0115\n",
      "Epoch 13/100\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 0.0104\n",
      "Epoch 14/100\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.0096\n",
      "Epoch 15/100\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.0092\n",
      "Epoch 16/100\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 0.0082\n",
      "Epoch 17/100\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.0079\n",
      "Epoch 18/100\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.0075\n",
      "Epoch 19/100\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.0071\n",
      "Epoch 20/100\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.0066\n",
      "Epoch 21/100\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.0064\n",
      "Epoch 22/100\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 0.0063\n",
      "Epoch 23/100\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.0060\n",
      "Epoch 24/100\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 0.0058\n",
      "Epoch 25/100\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.0057\n",
      "Epoch 26/100\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0056\n",
      "Epoch 27/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0052\n",
      "Epoch 28/100\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0051\n",
      "Epoch 29/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0050\n",
      "Epoch 30/100\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0046\n",
      "Epoch 31/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0045\n",
      "Epoch 32/100\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0045\n",
      "Epoch 33/100\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.0043\n",
      "Epoch 34/100\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0043\n",
      "Epoch 35/100\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0043\n",
      "Epoch 36/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0042\n",
      "Epoch 37/100\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0041\n",
      "Epoch 38/100\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0037\n",
      "Epoch 39/100\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0038\n",
      "Epoch 40/100\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0039\n",
      "Epoch 41/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0037\n",
      "Epoch 42/100\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0036\n",
      "Epoch 43/100\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0036\n",
      "Epoch 44/100\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0033\n",
      "Epoch 45/100\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0033\n",
      "Epoch 46/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0032\n",
      "Epoch 47/100\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0032\n",
      "Epoch 48/100\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0037\n",
      "Epoch 49/100\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0033\n",
      "Epoch 50/100\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0033\n",
      "Epoch 51/100\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0032\n",
      "Epoch 52/100\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0030\n",
      "Epoch 53/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0033\n",
      "Epoch 54/100\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0030\n",
      "Epoch 55/100\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0028\n",
      "Epoch 56/100\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0033\n",
      "Epoch 57/100\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0027\n",
      "Epoch 58/100\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0028\n",
      "Epoch 59/100\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.0029\n",
      "Epoch 60/100\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 0.0027\n",
      "Epoch 61/100\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0029\n",
      "Epoch 62/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0027\n",
      "Epoch 63/100\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0025\n",
      "Epoch 64/100\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0026\n",
      "Epoch 65/100\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0027\n",
      "Epoch 66/100\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0026\n",
      "Epoch 67/100\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0030\n",
      "Epoch 68/100\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0024\n",
      "Epoch 69/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0024\n",
      "Epoch 70/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0024\n",
      "Epoch 71/100\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0026\n",
      "Epoch 72/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0026\n",
      "Epoch 73/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0025\n",
      "Epoch 74/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0023\n",
      "Epoch 75/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0026\n",
      "Epoch 76/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0023\n",
      "Epoch 77/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0022\n",
      "Epoch 78/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0023\n",
      "Epoch 79/100\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0023\n",
      "Epoch 80/100\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0024\n",
      "Epoch 81/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0022\n",
      "Epoch 82/100\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0021\n",
      "Epoch 83/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0022\n",
      "Epoch 84/100\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0024\n",
      "Epoch 85/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0025\n",
      "Epoch 86/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0021\n",
      "Epoch 87/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0022\n",
      "Epoch 88/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0023\n",
      "Epoch 89/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0019\n",
      "Epoch 90/100\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0022\n",
      "Epoch 91/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0022\n",
      "Epoch 92/100\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0023\n",
      "Epoch 93/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0022\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0023\n",
      "Epoch 95/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0027\n",
      "Epoch 96/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0021\n",
      "Epoch 97/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0020\n",
      "Epoch 98/100\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0020\n",
      "Epoch 99/100\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0023\n",
      "Epoch 100/100\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25883412f08>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y, epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01273532, 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.76038051, 0.999     ],\n",
       "       [1.16355634, 0.999     ],\n",
       "       [0.03889084, 0.        ],\n",
       "       [0.82795948, 0.999     ],\n",
       "       [0.50485015, 0.999     ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.95678228, 0.999     ],\n",
       "       [0.        , 0.        ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.c_[model.predict(x[:10]), y[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 1.4006951e+00, -8.9346784e-01, -1.2880635e-01],\n",
       "        [-9.7655207e-03,  2.1995849e-03, -2.6192212e-01],\n",
       "        [ 4.3099943e-05,  4.3041253e-01, -6.2307787e-01]], dtype=float32),\n",
       " array([-0.59451354,  0.47829336,  0.        ], dtype=float32),\n",
       " array([[-1.4812533 , -0.79973626,  1.6194167 ],\n",
       "        [ 0.5627546 , -0.3893392 ,  0.83054477],\n",
       "        [ 0.21814847,  0.46995878,  0.595737  ]], dtype=float32),\n",
       " array([ 0.34383178,  0.        , -0.10780862], dtype=float32),\n",
       " array([[ 2.0093389],\n",
       "        [ 0.727564 ],\n",
       "        [-1.3644478]], dtype=float32),\n",
       " array([0.16349046], dtype=float32)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
